{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.spatial\n",
    "import scipy.optimize\n",
    "import json\n",
    "import cassiopeia as cass\n",
    "from cassiopeia import Position\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s2, s3), (s4, s5), ...\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"../resources/role_features.json\"\n",
    "RESOURCES_FILENAME = \"../resources/verification_set.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is my gather data script. It isn't pretty but it works. It uses some of the functionality below.\n",
    "# It also uses the training data here: https://github.com/Canisback/roleML/blob/master/verification_set.csv\n",
    "def gather_data(resources_filename):\n",
    "    positions_converter = {\n",
    "        'carry': Position.bottom,\n",
    "        'toplaner': Position.top,\n",
    "        'midlaner': Position.middle,\n",
    "        'support': Position.utility,\n",
    "        'jungler': Position.jungle\n",
    "    }\n",
    "\n",
    "    def parse_line(line):\n",
    "        line = line[1:-1]\n",
    "        line = [positions_converter.get(p) for p in line]\n",
    "        line.append(line.pop(1))\n",
    "        return line\n",
    "\n",
    "    with open(resources_filename) as f:\n",
    "        training = f.readlines()\n",
    "        training = [line.strip().split(',') for line in training]\n",
    "        header = training[0]\n",
    "        training = training[1:]\n",
    "    print(header)\n",
    "    print(training[0])\n",
    "    match_ids = [int(float(line[-1])) for line in training]\n",
    "    print(match_ids[0])\n",
    "\n",
    "    save = []\n",
    "    all_features = []\n",
    "    for i, matchid in enumerate(match_ids):\n",
    "        roles = parse_line(training[i])\n",
    "        match = Match(id=matchid, region='EUW')\n",
    "        for p in match.participants:\n",
    "            pid = p.id - 1\n",
    "            role = roles[pid]\n",
    "            #print(p.champion.name, role)\n",
    "            try:\n",
    "                features = get_features(p)\n",
    "                all_features.append(features)\n",
    "                save.append((matchid, pid, p.champion.id, role.value, features.tolist()))\n",
    "\n",
    "                # Check for errors\n",
    "                if features[1] == 0:\n",
    "                    # The summoner didn't buy any items???\n",
    "                    print(match.id, p.summoner.name, p.champion.name, f\"http://canisback.com:5050/game/EUW1/{match.id}\")\n",
    "            except:\n",
    "                pass\n",
    "        print(i, len(match_ids))\n",
    "\n",
    "    all_features = np.array(all_features)\n",
    "    print(all_features)\n",
    "\n",
    "    with open(FILENAME, 'w') as f:\n",
    "        json.dump(save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a ton of helper functions in order to calculate the feature list\n",
    "\n",
    "# These convert x,y positions to distances to top, mid, and bot lanes, which provides a better metric of position\n",
    "\n",
    "(XMIN, YMIN), (XMAX, YMAX) = (358, 461), (14589, 14673) # From another notebook. They were calculated by pulling a bunch of matches and finding the min/max positions of all events that occured in those matches. The goal was to get a bounding bot for highest/lowest position on the map for but x and y directions. This process yielded the numbers on this line.\n",
    "top_lane_position = np.array((XMIN, YMAX))\n",
    "mid_lane_position = np.array((XMAX/2, YMAX/2))\n",
    "bot_lane_position = np.array((XMAX, YMIN))\n",
    "\n",
    "def get_positions(vec):\n",
    "    positions = vec[4:]\n",
    "    positions = [(x,y) for x,y in pairwise(positions)]\n",
    "    return positions\n",
    "\n",
    "def get_top_mid_bot_dists(vec):\n",
    "    pos = get_positions(vec)\n",
    "    to_top = scipy.spatial.distance.cdist([top_lane_position], pos)[0] / 1000\n",
    "    to_mid = scipy.spatial.distance.cdist([mid_lane_position], pos)[0] / 1000\n",
    "    to_bot = scipy.spatial.distance.cdist([bot_lane_position], pos)[0] / 1000\n",
    "    return np.stack((to_top, to_mid, to_bot)).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 9 143\n"
     ]
    }
   ],
   "source": [
    "# These constants and functions are used in the feature generation and to convert the feature list to\n",
    "#  a one-hot vector\n",
    "\n",
    "STARTING_ITEMS = sorted((\n",
    "    \"Boots of Speed\",\n",
    "    \"Faerie Charm\",\n",
    "    \"Rejuvenation Bead\",\n",
    "    \"Sapphire Crystal\",\n",
    "    \"Ruby Crystal\",\n",
    "    \"Cloth Armor\",\n",
    "    \"Null-Magic Mantle\",\n",
    "    \"Long Sword\",\n",
    "    \"Hunter's Talisman\",\n",
    "    \"Hunter's Machete\",\n",
    "    \"Dagger\",\n",
    "    \"Brawler's Gloves\",\n",
    "    \"Amplifying Tome\",\n",
    "    \"Doran's Shield\",\n",
    "    \"Doran's Blade\",\n",
    "    \"Doran's Ring\",\n",
    "    \"The Dark Seal\",\n",
    "    \"Cull\",\n",
    "    \"Ancient Coin\",\n",
    "    \"Relic Shield\",\n",
    "    \"Spellthief's Edge\",\n",
    "    \"Corrupting Potion\"\n",
    "))\n",
    "\n",
    "SUMMONER_SPELLS = cass.get_summoner_spells(\"NA\")\n",
    "SUMMONER_SPELLS = sorted([spell.id for spell in SUMMONER_SPELLS if cass.GameMode.classic in spell.modes])\n",
    "CHAMPIONS = cass.get_champions(\"NA\")\n",
    "CHAMPIONS = sorted([champion.id for champion in CHAMPIONS])\n",
    "\n",
    "print(len(STARTING_ITEMS), len(SUMMONER_SPELLS), len(CHAMPIONS))\n",
    "\n",
    "#        (\n",
    "#            features['cs@12'],\n",
    "#            features['starting_item'],\n",
    "#            *features['summoner_spells'],\n",
    "#            *features['positions']\n",
    "#        )\n",
    "\n",
    "def feature_to_one_hot(feature):\n",
    "    starting_item_feature = np.zeros((len(STARTING_ITEMS),), dtype=bool)\n",
    "    item_index = int(feature[1]) - 1\n",
    "    if item_index >= 0:\n",
    "        starting_item_feature[item_index] = True\n",
    "    assert sum(starting_item_feature) in (0, 1)\n",
    "    ss_feature = np.zeros((len(SUMMONER_SPELLS),), dtype=bool)\n",
    "    ss_feature[int(feature[2])] = True\n",
    "    ss_feature[int(feature[3])] = True\n",
    "    assert sum(ss_feature) == 2\n",
    "    new = np.concatenate((feature[0:1], starting_item_feature, ss_feature, feature[4:]))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create the get_features function, which relies on the previous functionality\n",
    "\n",
    "def get_features(participant):\n",
    "    features = {\n",
    "        #\"champion\": CHAMPIONS.index(participant.champion.id),\n",
    "        \"positions\": [x for sublist in\n",
    "                [(frame.position.x, frame.position.y) for frame in participant.timeline.frames[1:-1]][:14]\n",
    "                for x in sublist\n",
    "            ],\n",
    "        \"starting_item\": next(iter([STARTING_ITEMS.index(item.name) + 1 for item in\n",
    "                sorted([item for item in participant.cumulative_timeline[\"2:00\"].items if item.name in STARTING_ITEMS], key=lambda item: item.gold.total)\n",
    "            ]), 0),\n",
    "        \"summoner_spells\": [SUMMONER_SPELLS.index(participant.summoner_spell_d.id), SUMMONER_SPELLS.index(participant.summoner_spell_f.id)],\n",
    "        \"cs@12\": participant.cumulative_timeline[\"12:00\"].creep_score\n",
    "    }\n",
    "    features = np.array(\n",
    "        (\n",
    "            #features['champion'],\n",
    "            features['cs@12'],\n",
    "            features['starting_item'],\n",
    "            *features['summoner_spells'],\n",
    "            *features['positions']\n",
    "        )\n",
    "    )\n",
    "    d = get_top_mid_bot_dists(features)\n",
    "    features = features[:4].tolist() + d\n",
    "    features = np.array(features)\n",
    "    \n",
    "    features = feature_to_one_hot(features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll split the features up by team in order to predict by-team rather than by-individual\n",
    "\n",
    "# WARNING: This requires the training data to be set up in a specific way.\n",
    "#  Namely, the participants in the data need to be in groups of 5 participants on the same team.\n",
    "#  That array of features is flattened, but still needs to be 5 participants on the same team in a row\n",
    "\n",
    "def split_features_by_team(features, teamsize=5):\n",
    "    teams = []\n",
    "    assert len(features) % teamsize == 0\n",
    "    for i in range(0, len(features), teamsize):\n",
    "        # Make sure the full_data has the same match id for all 5 team members\n",
    "        #match_ids = [full_data[j][0] for j in range(i, i+teamsize)]\n",
    "        #assert all(x == match_ids[0] for x in match_ids)\n",
    "        teams.append(features[i:i+teamsize])\n",
    "    teams = np.array(teams)\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above functions to load the training data\n",
    "\n",
    "LABELS = ['BOTTOM', 'JUNGLE', 'MIDDLE', 'TOP', 'UTILITY']\n",
    "\n",
    "def load_training_data(filename):\n",
    "    with open(filename) as f:\n",
    "        full_data = json.load(f)\n",
    "    # Drop matches where not all 10 participants were collected\n",
    "    match_counter = Counter()\n",
    "    for datum in full_data:\n",
    "        match_counter[datum[0]] += 1\n",
    "    skip = {match_id: count for match_id, count in match_counter.items() if count != 10}\n",
    "    full_data = [datum for datum in full_data if datum[0] not in skip]\n",
    "\n",
    "    # Convert x,y positions to distance to top, mid, bot\n",
    "    for i, datum in enumerate(full_data):\n",
    "        matchid, pid, cid, role, feat = datum\n",
    "        d = get_top_mid_bot_dists(feat)\n",
    "        feat = feat[:4] + d\n",
    "        full_data[i] = [matchid, pid, cid, role, feat]\n",
    "    \n",
    "    # Load labels\n",
    "    labels = []\n",
    "    features = []\n",
    "    for datum in full_data:\n",
    "        matchid, pid, cid, role, feat = datum\n",
    "        features.append(feat)\n",
    "        labels.append(LABELS.index(role))\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    one_hots = []\n",
    "    for feature in features:\n",
    "        one_hots.append(feature_to_one_hot(feature))\n",
    "    features = np.array(one_hots)\n",
    "    \n",
    "    teams = split_features_by_team(features)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "def train(features, labels):\n",
    "    clf = svm.SVC(gamma='scale', probability=True)\n",
    "    clf.fit(features, labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for predicting the roles from a match's team\n",
    "\n",
    "def _predict_team(team, clf, verbose=False):\n",
    "    assert len(team) == len(LABELS)\n",
    "    probs = 1 - clf.predict_proba(team)\n",
    "    row_ind, result = scipy.optimize.linear_sum_assignment(probs)\n",
    "    cost = probs[row_ind, result].sum() / len(team)\n",
    "    if verbose:\n",
    "        print(probs)\n",
    "        print(result)\n",
    "    return [LABELS[i] for i in result], cost\n",
    "\n",
    "def _predict_individuals(team, clf):\n",
    "    result = clf.predict(team)\n",
    "    return [LABELS[x] for x in result]\n",
    "\n",
    "def predict_team(team, verbose=False):\n",
    "    return _predict_team(team=team, clf=clf, verbose=verbose)  # abstract out the clf\n",
    "\n",
    "def predict_individuals(team, verbose=False):\n",
    "    return _predict_individuals(team=team, clf=clf)  # abstract out the clf\n",
    "\n",
    "def get_roles(team):\n",
    "    features = np.array([\n",
    "        get_features(p) for p in team.participants\n",
    "    ])\n",
    "    \n",
    "    roles, cost = predict_team(features)\n",
    "    result = {p: cass.Position(role) for p, role in zip(team.participants, roles)}\n",
    "    return result, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, training_labels = load_training_data(FILENAME)\n",
    "clf = train(training_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002050240253452973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Vayne': <Position.bottom: 'BOTTOM'>,\n",
       " 'Sylas': <Position.top: 'TOP'>,\n",
       " 'Braum': <Position.utility: 'UTILITY'>,\n",
       " 'Annie': <Position.middle: 'MIDDLE'>,\n",
       " 'Nocturne': <Position.jungle: 'JUNGLE'>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, let's grab some data and predict!\n",
    "\n",
    "cass.print_calls(False)\n",
    "me = cass.Summoner(name=\"Kalturi\", region=\"NA\")\n",
    "mh = me.match_history(queues={cass.Queue.ranked_solo_fives})\n",
    "m = mh[0]\n",
    "t = m.red_team\n",
    "roles, cost = get_roles(t)\n",
    "\n",
    "print(cost)\n",
    "{p.champion.name: role for p, role in roles.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
