{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.spatial\n",
    "import scipy.optimize\n",
    "import json\n",
    "import cassiopeia as cass\n",
    "from cassiopeia import Position, Match\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s2, s3), (s4, s5), ...\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFICATION_SET_FILENAME = \"./verification_set.csv\"\n",
    "FEATURES_FILENAME = \"./role_features.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_verificaiton_set(verification_set_filename):\n",
    "    with open(verification_set_filename) as f:\n",
    "        training = f.readlines()\n",
    "        training = [line.strip().split(',') for line in training]\n",
    "        header = training[0]\n",
    "        training = training[1:]\n",
    "        \n",
    "    header = header[1:-1]  # The last field is the game Id, the first is the row index\n",
    "    header = [int(pid) for pid in header]\n",
    "    resort = np.argsort(header)\n",
    "    \n",
    "    training = np.array(training)\n",
    "    match_ids = training[:, -1]\n",
    "    training = training[:, 1:-1]\n",
    "    training = training[:, resort]\n",
    "    training = training.tolist()\n",
    "    \n",
    "    assert len(match_ids) == len(training)\n",
    "    \n",
    "    # Convert to Cass Position enums\n",
    "    positions_converter = {\n",
    "        'carry': Position.bottom,\n",
    "        'toplaner': Position.top,\n",
    "        'midlaner': Position.middle,\n",
    "        'support': Position.utility,\n",
    "        'jungler': Position.jungle\n",
    "    }\n",
    "    good_data, bad_indices = [], []\n",
    "    for i, line in enumerate(training):\n",
    "        try:\n",
    "            good_data.append(\n",
    "                [positions_converter[p] for p in line]\n",
    "            )\n",
    "        except KeyError:\n",
    "            bad_indices.append(i)\n",
    "    training = np.array(good_data)\n",
    "    match_ids = np.array([match_id for i, match_id in enumerate(match_ids) if i not in bad_indices])\n",
    "    \n",
    "    match_ids = np.array(match_ids)\n",
    "    match_ids = match_ids.astype(np.float)\n",
    "    match_ids = match_ids.astype(int)\n",
    "    \n",
    "    assert len(match_ids) == len(training)\n",
    "    \n",
    "    return training, match_ids\n",
    "#load_verificaiton_set(VERIFICATION_SET_FILENAME);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a ton of helper functions in order to calculate the feature list\n",
    "\n",
    "# These convert x,y positions to distances to top, mid, and bot lanes, which provides a better metric of position\n",
    "\n",
    "(XMIN, YMIN), (XMAX, YMAX) = (358, 461), (14589, 14673) # From another notebook. They were calculated by pulling a bunch of matches and finding the min/max positions of all events that occured in those matches. The goal was to get a bounding bot for highest/lowest position on the map for but x and y directions. This process yielded the numbers on this line.\n",
    "top_lane_position = np.array((XMIN, YMAX))\n",
    "mid_lane_position = np.array((XMAX/2, YMAX/2))\n",
    "bot_lane_position = np.array((XMAX, YMIN))\n",
    "\n",
    "def get_top_mid_bot_dists(positions):\n",
    "    to_top = scipy.spatial.distance.cdist([top_lane_position], positions)[0]\n",
    "    to_mid = scipy.spatial.distance.cdist([mid_lane_position], positions)[0]\n",
    "    to_bot = scipy.spatial.distance.cdist([bot_lane_position], positions)[0]\n",
    "    return np.stack((to_top, to_mid, to_bot)).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 9 143\n"
     ]
    }
   ],
   "source": [
    "# These constants and functions are used in the feature generation\n",
    "\n",
    "STARTING_ITEMS = sorted((\n",
    "    \"Boots of Speed\",\n",
    "    \"Faerie Charm\",\n",
    "    \"Rejuvenation Bead\",\n",
    "    \"Sapphire Crystal\",\n",
    "    \"Ruby Crystal\",\n",
    "    \"Cloth Armor\",\n",
    "    \"Null-Magic Mantle\",\n",
    "    \"Long Sword\",\n",
    "    \"Hunter's Talisman\",\n",
    "    \"Hunter's Machete\",\n",
    "    \"Dagger\",\n",
    "    \"Brawler's Gloves\",\n",
    "    \"Amplifying Tome\",\n",
    "    \"Doran's Shield\",\n",
    "    \"Doran's Blade\",\n",
    "    \"Doran's Ring\",\n",
    "    \"The Dark Seal\",\n",
    "    \"Cull\",\n",
    "    \"Ancient Coin\",\n",
    "    \"Relic Shield\",\n",
    "    \"Spellthief's Edge\",\n",
    "    \"Corrupting Potion\"\n",
    "))\n",
    "\n",
    "SUMMONER_SPELLS = cass.get_summoner_spells(\"NA\")\n",
    "SUMMONER_SPELLS = sorted([spell.id for spell in SUMMONER_SPELLS if cass.GameMode.classic in spell.modes])\n",
    "CHAMPIONS = cass.get_champions(\"NA\")\n",
    "CHAMPIONS = sorted([champion.id for champion in CHAMPIONS])\n",
    "\n",
    "print(len(STARTING_ITEMS), len(SUMMONER_SPELLS), len(CHAMPIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create the get_features function, which relies on the previous functionality\n",
    "\n",
    "def _to_one_hot(features, nfeatures):\n",
    "    new = np.zeros((nfeatures,), dtype=bool)\n",
    "    for i in features:\n",
    "        new[i] = True\n",
    "    return new\n",
    "\n",
    "def _feature_CSat12(participant):\n",
    "    return [participant.cumulative_timeline[\"12:00\"].creep_score]\n",
    "\n",
    "def _feature_summoner_spells(participant):\n",
    "    spells = [SUMMONER_SPELLS.index(participant.summoner_spell_d.id),\n",
    "              SUMMONER_SPELLS.index(participant.summoner_spell_f.id)]\n",
    "    spells = _to_one_hot(spells, len(SUMMONER_SPELLS))\n",
    "    return spells\n",
    "\n",
    "def _feature_starting_item(participant):\n",
    "    # Sometimes the participant won't have bought an item at 2:00 yet. In that case, set to -1.\n",
    "    item_index = next(iter([STARTING_ITEMS.index(item.name) for item in\n",
    "        sorted([item for item in participant.cumulative_timeline[\"2:00\"].items\n",
    "                if item.name in STARTING_ITEMS],\n",
    "               key=lambda item: item.gold.total)\n",
    "    ]), -1)\n",
    "    \n",
    "    # Manually do the one-hot encoding because of the special case for 0.\n",
    "    starting_item_feature = np.zeros((len(STARTING_ITEMS),), dtype=bool)\n",
    "    if item_index >= 0:\n",
    "        starting_item_feature[item_index] = True\n",
    "    assert sum(starting_item_feature) in (0, 1)\n",
    "    \n",
    "    return starting_item_feature\n",
    "\n",
    "def _feature_positions(participant):\n",
    "    nframes = 11\n",
    "    positions = [(frame.position.x, frame.position.y) for frame in participant.timeline.frames[1:-1]][:nframes]\n",
    "    if len(positions) != nframes:\n",
    "        raise ValueError(\"Not enough frames in match.\")\n",
    "    positions = get_top_mid_bot_dists(positions)\n",
    "    positions = np.array(positions) / 1000\n",
    "    positions = positions.tolist()\n",
    "    return positions\n",
    "\n",
    "def _feature_champion(participant):\n",
    "    champion = CHAMPIONS.index(participant.champion.id)\n",
    "    return [champion]\n",
    "\n",
    "def _feature_XP(participant):\n",
    "    nframes = 11\n",
    "    xp = [frame.experience / 1000 for frame in participant.timeline.frames[1:-1]][:nframes]\n",
    "    if len(xp) != nframes:\n",
    "        raise ValueError(\"Not enough frames in match.\")\n",
    "    return xp\n",
    "\n",
    "def get_features(participant):\n",
    "    features = {\n",
    "        \"positions\": _feature_positions(participant),\n",
    "        \"starting_item\": _feature_starting_item(participant),\n",
    "        \"summoner_spells\": _feature_summoner_spells(participant),\n",
    "        \"cs@12\": _feature_CSat12(participant),\n",
    "        \"xp\": _feature_XP(participant)\n",
    "    }\n",
    "    features = np.array((\n",
    "        *features['cs@12'],\n",
    "        *features['starting_item'],\n",
    "        *features['summoner_spells'],\n",
    "        *features['positions'],\n",
    "        *features['xp']\n",
    "    ))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is my gather data script. It isn't pretty but it works. It uses some of the functionality below.\n",
    "# It also uses the training data here: https://github.com/Canisback/roleML/blob/master/verification_set.csv\n",
    "\n",
    "def collect_team_data(team, roles):\n",
    "    data = []\n",
    "    for p, role in zip(team.participants, roles):\n",
    "        features = get_features(p)\n",
    "        data.append({\n",
    "            \"championId\": p.champion.id,\n",
    "            \"role\": role.value,\n",
    "            \"features\": features.tolist()\n",
    "        })\n",
    "    return data\n",
    "\n",
    "\n",
    "def gather_data(resources_filename, output_filename):\n",
    "    match_roles, match_ids = load_verificaiton_set(resources_filename)\n",
    "\n",
    "    save = []\n",
    "    all_features = []\n",
    "    for match_id, roles in zip(match_ids, match_roles):\n",
    "        match_id = int(match_id)\n",
    "        match = Match(id=match_id, region='EUW')\n",
    "        blue_team, red_team = match.blue_team, match.red_team\n",
    "        blue_roles = [roles[p.id - 1] for p in blue_team.participants]\n",
    "        red_roles = [roles[p.id - 1] for p in red_team.participants]\n",
    "        try:\n",
    "            participant_data = collect_team_data(blue_team, blue_roles)\n",
    "            blue_data = {\n",
    "                \"matchId\": match_id,   \n",
    "                \"team\": \"BLUE\",\n",
    "                \"participantData\": participant_data\n",
    "            }\n",
    "            save.append(blue_data)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            participant_data = collect_team_data(red_team, red_roles)\n",
    "            red_data = {\n",
    "                \"matchId\": match_id,   \n",
    "                \"team\": \"RED\",\n",
    "                \"participantData\": participant_data\n",
    "            }\n",
    "            save.append(red_data)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(len(save)/2, len(match_ids))\n",
    "\n",
    "    with open(output_filename, 'w') as f:\n",
    "        json.dump(save, f)\n",
    "\n",
    "#gather_data(VERIFICATION_SET_FILENAME, FEATURES_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll split the features up by team in order to predict by-team rather than by-individual\n",
    "\n",
    "# WARNING: This requires the training data to be set up in a specific way.\n",
    "#  Namely, the participants in the data need to be in groups of 5 participants on the same team.\n",
    "#  That array of features is flattened, but still needs to be 5 participants on the same team in a row\n",
    "\n",
    "def split_features_by_team(features, teamsize=5):\n",
    "    teams = []\n",
    "    assert len(features) % teamsize == 0\n",
    "    for i in range(0, len(features), teamsize):\n",
    "        teams.append(features[i:i+teamsize])\n",
    "    teams = np.array(teams)\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above functions to load the training data\n",
    "\n",
    "LABELS = ['BOTTOM', 'JUNGLE', 'MIDDLE', 'TOP', 'UTILITY']\n",
    "\n",
    "def load_training_data(filename):\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    champion_ids = []\n",
    "    for team in data:\n",
    "        for p in team['participantData']:\n",
    "            features.append(p['features'])\n",
    "            labels.append(p['role'])\n",
    "            champion_ids.append(p['championId'])\n",
    "    features = np.array(features)\n",
    "        \n",
    "    subtract = np.zeros((features.shape[1]))\n",
    "    divide = np.ones_like(subtract)\n",
    "    print(subtract.shape)\n",
    "    for j, col in enumerate(features.T):\n",
    "        subtract[j] = col.min()\n",
    "        divide[j] = col.max() - subtract[j]\n",
    "        if divide[j] == 0:\n",
    "            divide[j] = 1\n",
    "    \n",
    "    return features, labels, champion_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "\n",
    "def train(features, labels):\n",
    "    clf = svm.SVC(gamma='scale', probability=True)\n",
    "    clf.fit(features, labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for predicting the roles from a match's team\n",
    "\n",
    "def predict_individuals(team, clf):\n",
    "    result = clf.predict(team)\n",
    "    return [LABELS[x] for x in result]\n",
    "\n",
    "def predict_team(team, clf, verbose=False):\n",
    "    assert len(team) == len(LABELS)\n",
    "    probs = 1 - clf.predict_proba(team)\n",
    "    print(probs)\n",
    "    row_ind, result = scipy.optimize.linear_sum_assignment(probs)\n",
    "    cost = probs[row_ind, result].sum() / len(team)\n",
    "    if verbose:\n",
    "        print(probs)\n",
    "        print(result)\n",
    "    return [LABELS[i] for i in result], cost\n",
    "\n",
    "def get_roles(team):\n",
    "    features = np.array([\n",
    "        get_features(p) for p in team.participants\n",
    "    ])\n",
    "    \n",
    "    roles, cost = predict_team(features, clf)\n",
    "    result = {p: cass.Position(role) for p, role in zip(team.participants, roles)}\n",
    "    return result, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76,)\n",
      "[49.55200683  0.00170794  0.03005978  0.00375747  0.          0.00102477\n",
      "  0.07702818  0.00153715  0.00017079  0.21417592  0.13373185  0.10128096\n",
      "  0.00102477  0.10623399  0.0852263   0.03569599  0.          0.00836892\n",
      "  0.05311699  0.00153715  0.00563621  0.11426132  0.02134927  0.00614859\n",
      "  0.04730999  0.99180188  0.00939368  0.20102477  0.20051238  0.17028181\n",
      "  0.33287788  0.04064902 11.47515711 11.75073756 11.42649922 11.61379847\n",
      " 11.82552619 11.88268817 11.94985986 11.87669553 11.71388671 11.82156623\n",
      " 11.86736357  4.06160447  5.24514038  5.29536894  5.5024527   5.59441048\n",
      "  5.55835968  5.49222493  5.51600642  5.50969593  5.57962089  5.46971392\n",
      "  9.37937922  8.62578348  9.16702144  9.31413508  9.30015351  9.20684739\n",
      "  9.10424935  9.22270453  9.36484923  9.33441796  9.24799074  0.00053681\n",
      "  0.1849585   0.60669291  1.02009923  1.44191734  1.84028335  2.24632161\n",
      "  2.69241452  3.11253271  3.54152229  3.99905807]\n"
     ]
    }
   ],
   "source": [
    "features, labels, champion_ids = load_training_data(FEATURES_FILENAME)\n",
    "print(np.mean(features, axis=0))\n",
    "clf = train(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99744681 0.9965812  0.9991453  0.9991453  0.9991453 ]\n",
      "Accuracy: 99.83 (+/- 0.22)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, features, labels, cv=5)\n",
    "print(scores)\n",
    "scores *= 100\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00155725 0.99986402 0.99970421 0.99961111 0.9992634 ]\n",
      " [0.99870535 0.99911211 0.99867543 0.00410433 0.99940278]\n",
      " [0.99999935 0.99999929 0.99999975 0.99999972 0.00000189]\n",
      " [0.99808185 0.99947598 0.00371133 0.99921536 0.99951547]\n",
      " [0.99999944 0.00071293 0.99983701 0.99982135 0.99962927]]\n",
      "0.0020175455450013534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Vayne': <Position.bottom: 'BOTTOM'>,\n",
       " 'Sylas': <Position.top: 'TOP'>,\n",
       " 'Braum': <Position.utility: 'UTILITY'>,\n",
       " 'Annie': <Position.middle: 'MIDDLE'>,\n",
       " 'Nocturne': <Position.jungle: 'JUNGLE'>}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, let's grab some data and predict!\n",
    "\n",
    "cass.print_calls(False)\n",
    "me = cass.Summoner(name=\"Kalturi\", region=\"NA\")\n",
    "mh = me.match_history(queues={cass.Queue.ranked_solo_fives})\n",
    "m = mh[0]\n",
    "t = m.red_team\n",
    "roles, cost = get_roles(t)\n",
    "\n",
    "print(cost)\n",
    "{p.champion.name: role for p, role in roles.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
